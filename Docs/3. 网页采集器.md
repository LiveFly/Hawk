
##  1.基本入门

网页采集器模拟了浏览器的设计，填入网址，点击刷新，即可获取对应地址的html源码。

左侧的区域，显示了html源码和浏览器视图，可通过tab页切换。右侧配置区域，可对关键字进行搜索，并对面前所有的属性进行管理。

概念解释：
- url： 以http打头的网页地址，Hawk3也能支持类似`C://a.html`的本地文件。
- 手气不错： Hawk的一种自动化抓取关键数据的方法，极大地减少了劳动
- 属性： 每增加一个属性，采集器抓取的数据，就会多一列。
- XPath和CssSelector:  它们都是描述元素在HTML树中位置的表达，后者更简洁，Hawk3同时支持这两种表达，但手气不错的结果都是XPath。 可参考互联网上的相关概念

Hawk把网页分成两种类型:

 - 列表(List)->多文档模式
   - 如二手房房源信息
   - 某个购物清单
 - 普通文档（One）->单文档模式
   - 如京东的某个商品页面
   - 某条新闻页面
 - 当你没有为网页采集器添加任何属性时，默认行为是返回只有一个字段`Content`的单文档，内容为整个页面。可以显式指定为NoTransform来支持这个模式。



## 2. 纯手动模式

由于软件不知道到底要获取哪些内容，因此需要手工给定几个关键字， 让Hawk搜索关键字， 并获取位置。填入搜索字符， 发现能够成功获取XPath, 编写属性名称，点击**添加字段**，即可添加一个属性。类似地，再填入30535，设置属性名称为“单价”，即可添加另外一个属性。

在`搜索属性`的文本框中，输入你要获取的关键字，由于关键字在网页中可能出现多次，可连续点击`继续搜索`，在多个结果间切换，左侧的html源码会对搜索的结果进行高亮。
> 请注意观察搜索的关键字在网页中的位置，是否符合预期，否则抓取数据可能会有问题。尤其在List模式。
> 如果需要抓取本页面的多块数据，可新建多个`网页采集器`，分别进行配置。

如果发现有错误，可点击**编辑集合**，对属性进行删除，修改和排序。

你可以类似的将所有要抓取的特征字段添加进去，或是直接点击**手气不错**，系统会根据目前的属性，推测其他属性。


## 3. 手气不错

这是Hawk最被人称赞的功能！在新的Hawk3中，该功能被极大地增强。

### 3.1 List模式的手气不错

在List模式下，一般来说，输入网址加载页面后，点击`手气不错`即可，Hawk会自动按照优先级将列表数据抓取出来。
//补充图片

左右切换选择你想要的数据集，之后在下面的属性栏对结果进行微调。

下面的图标可以全选，反选所有属性，点击`删除`即可删除选中的属性，亦可对属性名称进行修改。 点击`刷新`即可更新结果。 

添加一个属性，手气不错就能更准确地进行。添加两个属性，即可选定唯一区域。

## 3.1 One模式的手气不错

Hawk3新增功能，当网页中包含多达几十种属性时，挨个添加会变得特别烦琐，这在某种商品属性页特别常见。

为了解决这个问题，将关键字加入到`搜索属性`中，此时不要将其添加到属性列表中，直接点击`手气不错`即可。 

是不是很amazing? 欢迎给作者打赏！ 

##  3.2  原理

网页采集器的功能是获取网页中的数据（废话）。通常来说，目标可能是列表（如购物车列表），或是一个页面中的固定字段（如JD某商品的价格和介绍，在页面中只有一个）。因此需要设置其读取模式。传统的采集器需要编写正则表达式，但方法过分复杂。

如果认识到html是一棵树，只要找到了承载数据的节点即可，之后用XPath来描述。

![image_1b0keius5171011j6l911tsg109fg.png-98.2kB][1]

手工编写XPath也很复杂，因此软件可以通过关键字，自动检索XPath，提供关键字，软件就会从树中递归搜索包含该数据的叶子节点。因此关键字最好是在页面中独一无二的。

如上图所示，只要提供“北京”和“42”这两个关键字，就能找到parent节点， 进而获取div[0]和div[1]这两个列表元素。通过div[0]和div[1]两个节点的比较，我们就能自动发现相同的子节点（name,mount）和不同的节点（北京:上海,37:42）。相同的节点会保存为属性名，不同的节点为属性值。但是，不能提供`北京`和`37`，此时，公共节点是`div[0]`， 这不是列表。

软件在不提供关键字的情况下，也能通过html文档的特征，去计算最可能是列表父节点（如图中的parent）的节点，但当网页特别复杂时，猜测可能会出错。

本算法原理是原创的，可查看源码或留言交流。


## 4. 结果检查

工作过程中，可点击**提取测试** ，随时查看采集器目前的能够抓取的数据内容。在属性管理器的上方，可以修改采集器的模块名称，这样就方便**数据清洗** 模块调用该采集器。


## 5. 对请求进行设置

当出现乱码，或者希望自己填入cookie等请求头时，可在`属性对话框`点击`请求详情`，弹出的对话框中进行设置。有时为了简便，可以将浏览器中的requests请求头直接拷贝到`请求参数`中。

Hawk有一定的网页编码检测功能，但出现乱码时，可以将编码从GB2312设置为UTF8，即可解决大多数乱码问题。

如何调用网页采集器，或实现Post请求？ 参考`4.1节：从爬虫转换`

## 6. 具体的例子


以抓取新闻内容为例：
`http://www.ce.cn/xwzx/gnsz/gdxw/201609/21/t20160921_16119449.shtml`
页面如下：
![image_1at5pff7g7m71jtq1b2o1hlq1dt9.png-76.5kB][8]

你可以在搜索关键字中，搜索【2016年09月21日】，属性填写为时间，搜索【人民日报】，属性为【来源】。

提取正文需要注意，你可以随意填写正文中的一部分关键字，例如【量子隐形传态是一种传递量子】，这样Hawk就检索出了XPath:
`前面省略/div[1]/p[1]`

如果你直接使用这个路径，则抓取的内容只有这一段。为了抓取正文，我们可以将`/p[1]`部分去掉，只获取其父节点。这样就能抓取全文数据（是不是很赞）？

如果你想获取原始正文的html，则在属性列表的对话框里，可以勾选某个属性的【HTML标签】。

此时，点击提取测试，看看是不是获取了所需的数据？


  [1]: http://static.zybuluo.com/buptzym/y0l0aorvdas5ydsg8xcz9jx2/image_1b0keius5171011j6l911tsg109fg.png
  [2]: https://github.com/ferventdesert/Hawk/wiki/4.3-%E8%BD%AC%E6%8D%A2%E5%99%A8#%E5%8D%95%E8%BD%AC%E5%A4%9A%E6%96%87%E6%A1%A3%E7%9A%84%E7%89%B9%E5%88%AB%E8%AF%B4%E6%98%8E