# 数据库和文件读写 

---

我们将所有与Hawk数据读写相关的内容都汇总在这个章节，方便总结和查阅。

## 1. 数据清洗的相关模块


| 名称 | 类型  | 影响内容  | 参数 | 输入列 
| --  | --   |  --  |  -- |  -- |
| 读取文件文本 | 生成器| 文本 | 文件路径 |   | 
| 读取文件数据 | 生成器| 数据 |  文件路径 |   |
| 从数据表生成 | 生成器| 数据表 | 数据表名称     |   |
| 从数据库生成 | 生成器 | 数据库 |  数据库名称和表名 |   | 
| 写入文件文本 | 执行器| 文本 |  文件路径  | 文件内容 |
| 写入文件数据  | 执行器| 不支持 |   |  无  |   
| 写入数据表 | 执行器 | 数据表 | 数据表名称    |   无 |
| 写入数据库  | 执行器| 数据库 | 数据库名称和表名    | 无   |
| 保存超链接文件  | 执行器| 文件 | 保存地址    | 超链接地址  |
| 获取文件夹文件  | 生成器| 文件名 | 文件夹路径    | 文件地址  |



从模块名称上，就能知道模块的功能，不过这里还是要解释一下：
1. 文件文本和文件数据的区别：前者是纯文本，后者是读取csv,excel等获得的文档数据
2. 数据表与数据库的区别： 前者是Hawk内存中的表，后者是连接器连接的数据库，需要提前配置
3. 为什么没有`写入文件数据`？  因为并行模式下写文件可能会有问题，因此建议将数据写到数据表或者库里后，再将其导出到文件

举个例子，如果某一列是文件名，之后希望分别读取每个文件内的文本，放到新的列里，就可以使用`读取文件文本`， 路径通过参数传入，并使用方括号表达式。

### 1.2 保存超链接文件

由于本模块非常重要，重点讲解：
- 拖入的列为文件的超链接地址
- `保存位置`:可以使用方括号表达式，将某一列的内容传递过来

这特别适合抓取网页中的图片，文档等内容。

值得注意的是，一些网站必须要求登录以后才能访问这些内容。而如果你已经配置好了一个能用的`网页采集器`，那么就可以在`爬虫选择`（我现在在飞机上，实在记不得那个属性叫什么名字了）填写这个采集器的名称，此时模块会使用那个采集器的header进行抓取。



## 2. 读写文件数据

除了一般的数据库导入导出，Hawk还支持从文件导入和导出，支持的文件类型包括：

 - Excel
 - CSV(逗号分割文本文件)
 - TXT (制表符分割文本文件)
 - Json
 - xml

### 2.1 Excel
目前来看，Excel使用最多，Hawk2在导出到Excel有严重的性能问题， 受限于NPOI库，数据在几万条之后，会越导越慢。在Hawk3本问题得到了极大地缓解。因此在导出数据时，建议默认使用Excel

> 大型Excel的读入，Hawk3依然有问题。

### 2.2 CSV和TXT

注意编码格式的问题，同时还一定要留意文本中本身包含制表符或换行符的情况。这种情况下，系统会默认将所有文本内包含的特殊字符进行转义。CSV和TXT不存在性能问题，理论上可以支持无限大的文本写入。

因此完全可以在写入CSV和TXT后，再将其手动导入Excel等应用。

## 2.3 Json和 XML

在大数据情况下Json的存储效率明显高很多，建议使用Json.

综上，如果您的数据不大，建议使用Excel，如果数据量较大，可以考虑TXT和Json.

## 3. 数据库

MongoDB需要安装，而Sqlite不需安装，建议使用Sqlite.
###  3.1 安装MongoDB
已经安装过的可以自行跳过。
可以从这里下载笔者已经打包好的安装包，之后解压后，在bat脚本上点击右键，以管理员模式执行，就会默认安装到D盘上并启动服务，非常方便。

> https://files.cnblogs.com/files/buptzym/mongodb_windows.zip

MongoDB本身包含32位和64位两种版本，前者只支持最大2GB的数据集合。但32位能装在64位系统上，反过来就不成。因此提供的安装包是32位版本的。如果想装64位，可以参考网络上其他教程。

安装之后，可以在任务管理器的`服务`上，检查是否已经包含了`正在运行`的MongoDB服务。

### 3.2 如何为Hawk添加连接器

在`连接管理`的空白处，右键新建即可。

如何读取数据库呢？两种方式

#### 事先导入数据管理器

添加连接器后，可以在下拉菜单中看到当前数据库中包含的所有表，在表上点右键，可选择
 - 【查看数据】：查看内容，并不导入到内存中
 - 【导入全部数据】：将表内容全部导入到内存中，表格巨大时慎用！
 - 【执行查询】，此时会弹出对话框，可在对话框中输入Mongo支持的js语法，即可执行查询并导入到内存中。本功能没有经过详细测试，慎用。
 
 之后，可以利用数据清洗，对这些数据进行后处理或导出。

#### 在数据清洗中动态导入

可选择`从数据库生成`，此时每次刷新时，系统都会从数据库内实时地获取数据，整个流不会将数据全部导入到内存中。

两种方法可以按需求选用，对第一种方法，每次刷新时性能很高，因为数据已经在内存中了，但如果表大则是灾难；对第二种，不论表多大都没有关系，但刷新时每次都要请求数据库，因此性能相对较差。


### 3.3 如何写入数据库

参考本文的第一节。

